{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing datasets for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../cfg/config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets\n",
    "data_dir = config['FILES']['data_dir']\n",
    "dfs = {name: pd.read_csv(os.path.join(data_dir, file)).drop(columns=['index'], errors='ignore')\n",
    "       for name, file in config['FILES'].items() if name != 'data_dir'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing main infos\n",
    "for name, df in dfs.items():\n",
    "    print(f\"Dataset '{name}':\")\n",
    "    print(f\"- Shape: {df.shape}\")\n",
    "    print(f\"- Columns: {df.columns.tolist()}\")\n",
    "    print(\"- First rows:\")\n",
    "    print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets focusing on customer-centric analysis\n",
    "customer_orders_df = dfs['customers'].merge(dfs['orders'], on='customer_id', how='left')\n",
    "customer_orders_df = customer_orders_df.merge(dfs['order_items'], on='order_id', how='left')\n",
    "customer_orders_df = customer_orders_df.merge(dfs['order_pymts'], on='order_id', how='left')\n",
    "customer_orders_df = customer_orders_df.merge(dfs['order_reviews'][['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "#selecting coherent variables\n",
    "selected_columns = [\n",
    "    'customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state',\n",
    "    'order_id', 'order_status', 'order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date',\n",
    "    'product_id', 'price', 'freight_value', 'payment_type', 'payment_installments', 'payment_value', 'review_score'\n",
    "]\n",
    "customer_orders_df = customer_orders_df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display information about the customer-centric merged dataset\n",
    "print(f\"Customer-centric Merged Dataset:\")\n",
    "print(f\"- Shape: {customer_orders_df.shape}\")\n",
    "print(f\"- Columns: {customer_orders_df.columns.tolist()}\")\n",
    "print(\"- First rows:\")\n",
    "print(customer_orders_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling data fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle missing values\n",
    "for col in ['price', 'freight_value', 'payment_installments', 'payment_value', 'review_score']:\n",
    "    customer_orders_df[col].fillna(customer_orders_df[col].median(), inplace=True)\n",
    "\n",
    "for col in ['customer_state', 'payment_type']:\n",
    "    customer_orders_df[col].fillna(customer_orders_df[col].mode()[0], inplace=True)\n",
    "\n",
    "#drop rows with any remaining NaN\n",
    "customer_orders_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature preparation\n",
    "numerical_features = ['price', 'freight_value', 'payment_installments', 'payment_value', 'review_score']\n",
    "categorical_features = ['customer_state', 'payment_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(customer_orders_df)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for clustering evaluation and visualization\n",
    "def evaluate_and_visualize(X, labels, title):\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    print(f\"{title} Silhouette Score: {silhouette_avg:.3f}\")\n",
    "    X_embedded = TSNE(n_components=2, random_state=42).fit_transform(X)\n",
    "    plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=labels, cmap='viridis', s=50)\n",
    "    plt.title(f\"T-SNE visualization of {title}\")\n",
    "    plt.xlabel(\"TSNE Component 1\")\n",
    "    plt.ylabel(\"TSNE Component 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=random_state)\n",
    "labels_kmeans = kmeans.fit_predict(X)\n",
    "evaluate_and_visualize(X, labels_kmeans, \"KMeans clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=5, random_state=random_state)\n",
    "labels_gmm = gmm.fit_predict(X)\n",
    "evaluate_and_visualize(X, labels_gmm, \"GMM clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo = AgglomerativeClustering(n_clusters=5)\n",
    "labels_agglo = agglo.fit_predict(X)\n",
    "evaluate_and_visualize(X, labels_agglo, \"Hierarchical clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels_dbscan = dbscan.fit_predict(X)\n",
    "evaluate_and_visualize(X, labels_dbscan, \"DBSCAN clusters\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
